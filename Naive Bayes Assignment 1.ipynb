{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ebfc4d7-bd88-4a02-9f74-2ae96bbfdb1c",
   "metadata": {},
   "source": [
    "#  Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b775ed-841a-4da7-bdd0-de9e8132ebc0",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f7cff2-9266-4e24-aeae-b5e166f4b75b",
   "metadata": {},
   "source": [
    "Bayes' theorem is a fundamental concept in probability theory and statistics that describes the probability of an event, given prior knowledge or information. It's named after the 18th-century British mathematician and theologian, Thomas Bayes, who developed the foundational principles behind this theorem. Bayes' theorem is particularly useful in situations involving conditional probability, where you have some initial information or evidence and want to update your beliefs based on new data.\n",
    "\n",
    "The key idea behind Bayes' theorem is that you can update your belief about the probability of event A occurring, given new evidence (event B), by considering both the prior probability of A and the likelihood of B occurring given A.\n",
    "\n",
    "This theorem has applications in various fields, including statistics, machine learning, and artificial intelligence. It's a fundamental building block for Bayesian inference, which is a powerful method for updating probabilities as new information becomes available, making it a valuable tool for decision-making and probabilistic reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ffa951-d8ea-4fcc-b1cd-560f0ed0cc8c",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd8cd2-8ba2-446e-aff0-00b9eb0da13f",
   "metadata": {},
   "source": [
    "The theorem can be expressed as follows, where A and B are events, and P(B) is not zero:\n",
    "\n",
    "P(A|B) = ( P(B|A) * P(A) ) / P(B)\n",
    "\n",
    "In words, this can be interpreted as:\n",
    "\n",
    "- \\( P(A|B) \\): The probability of event A occurring given that event B has occurred.\n",
    "- \\( P(B|A) \\): The probability of event B occurring given that event A has occurred.\n",
    "- \\( P(A) \\): The prior probability of event A occurring.\n",
    "- \\( P(B) \\): The prior probability of event B occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e43d47-d34a-43d1-9ebb-d39292316014",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31a786-ee1e-4185-bbb5-9c8a7a47335f",
   "metadata": {},
   "source": [
    "Imagine you have a regular six-sided dice, and you're interested in finding the probability of rolling a 6, given that you know the outcome is an even number.\n",
    "\n",
    "1. **Prior Probability (Initial Belief)**:\n",
    "   - The probability of rolling a 6 on a fair six-sided dice is  P(6) = 1/6\n",
    "  P(even) = 3/6\n",
    "   - The probability of rolling an even number on a fair six-sided dice is P(even) = 3/6 because there are three even numbers (2, 4, and 6) out of the total six possible outcomes.\n",
    "\n",
    "2. **New Evidence**:\n",
    "   - We know that the outcome is an even number, which means we have new evidence P(even) = 1\n",
    "\n",
    "We want to find the **conditional probability** of rolling a 6 given that the outcome is an even number\n",
    "\n",
    "Using Bayes' theorem:\n",
    "P(6|even) = P(even|6) * P(6) / P(even)\n",
    "\n",
    "Plug in the values:\n",
    "\n",
    "P(6|even) = (1 * (1/6)) / (3/6)\n",
    "\n",
    "Simplify:\n",
    "\n",
    "  P(6|even) = 1/3\n",
    "\n",
    "So, the probability of rolling a 6, given that the outcome is an even number, is P(6|even) = 1/3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed476e4-9210-4d96-ad57-44d6f37afd32",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a834de-e139-4bde-ae32-f4884ec680db",
   "metadata": {},
   "source": [
    "Bayes' theorem and conditional probability are closely related concepts, and Bayes' theorem can be thought of as a way to compute conditional probabilities when you have additional information or evidence.\n",
    "\n",
    "**Conditional Probability:** Conditional probability is the probability of an event (A) occurring given that another event (B) has already occurred. It's denoted as P(A|B), and it measures the likelihood of event A happening within the context of event B.\n",
    "\n",
    "**Bayes' Theorem:** Bayes' theorem provides a way to compute conditional probabilities when you know the reverse conditional probability and the prior probabilities of the individual events involved. The theorem allows you to update your beliefs about the likelihood of an event, given new evidence (B), by considering the initial beliefs (prior probabilities) and the likelihood of observing the new evidence if the event of interest (A) were true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1dfee-3e1c-4526-807a-63f78d66d0b5",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa21b9a-eada-4232-b484-494277b18760",
   "metadata": {},
   "source": [
    "\n",
    "1. **Gaussian Naive Bayes**:\n",
    "   - \"Gaussian Naive Bayes is suitable for features that can be modeled with a normal distribution, whether they are continuous or discrete.\"\n",
    "   - Gaussian Naive Bayes can handle features following a normal distribution, even if they are discrete.\n",
    "\n",
    "2. **Multinomial Naive Bayes**:\n",
    "   - \"Multinomial Naive Bayes is often used for problems where features can be represented as counts or frequencies, such as text classification, but it can also be applied to other types of data.\"\n",
    "   - Multinomial Naive Bayes has broader applicability beyond text classification, including cases where features can be represented as counts or frequencies, such as image classification.\n",
    "\n",
    "3. **Bernoulli Naive Bayes**:\n",
    "\n",
    "    - Assumption: Assumes binary (0/1) features, where each feature represents the presence (1) or absence (0) of a particular attribute.\n",
    "     - Useful for binary data, such as text classification where you're interested in whether a specific word occurs in a document (1 if it does, 0 if it doesn't). Also applicable to other types of binary data, like user preferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214b622-d232-4e6c-950a-ffe1eb926da3",
   "metadata": {},
   "source": [
    "### Q6. Assignment:\n",
    "\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "\n",
    "|Class| X1=1 | X1=2 |X1=3| X2=1 |X2=2| X2=3 |X2=4|\n",
    "|-----|------|------|----|------|-----|-----|-----|\n",
    "|    A |3 |3| 4| 4| 3| 3| 3|\n",
    "|B |2| 2| 1| 2| 2| 2| 3|\n",
    "\n",
    "\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad532d1-6de8-4bbc-b05c-484a184e2304",
   "metadata": {},
   "source": [
    "\n",
    "The Naive Bayes classifier will predict the class of a new instance by calculating the posterior probability of each class, given the features of the new instance. The class with the highest posterior probability will be the class that the Naive Bayes classifier predicts.\n",
    "\n",
    "In this case, the prior probabilities of the two classes are equal. So, we need to calculate the conditional probability of the new instance belonging to class A, given the features X1 = 3 and X2 = 4, and the conditional probability of the new instance belonging to class B, given the features X1 = 3 and X2 = 4.\n",
    "\n",
    "The conditional probability of the new instance belonging to class A can be calculated as follows:\n",
    "\n",
    "```\n",
    "P(A|X1=3, X2=4) = P(X1=3, X2=4|A) * P(A) / P(X1=3, X2=4)\n",
    "```\n",
    "\n",
    "The probability of the features X1 = 3 and X2 = 4 occurring together in class A is 4/10. The prior probability of class A is 1/2. The probability of the features X1 = 3 and X2 = 4 occurring together in the entire dataset is 7/10. So, the conditional probability of the new instance belonging to class A can be calculated as follows:\n",
    "\n",
    "```\n",
    "P(A|X1=3, X2=4) = (4/10) * (1/2) / (7/10) = 2/7\n",
    "```\n",
    "\n",
    "The conditional probability of the new instance belonging to class B can be calculated as follows:\n",
    "\n",
    "```\n",
    "P(B|X1=3, X2=4) = P(X1=3, X2=4|B) * P(B) / P(X1=3, X2=4)\n",
    "```\n",
    "\n",
    "The probability of the features X1 = 3 and X2 = 4 occurring together in class B is 3/10. The prior probability of class B is 1/2. The probability of the features X1 = 3 and X2 = 4 occurring together in the entire dataset is 7/10. So, the conditional probability of the new instance belonging to class B can be calculated as follows:\n",
    "\n",
    "```\n",
    "P(B|X1=3, X2=4) = (3/10) * (1/2) / (7/10) = 3/14\n",
    "```\n",
    "\n",
    "Since the conditional probability of the new instance belonging to class A is greater than the conditional probability of the new instance belonging to class B, the Naive Bayes classifier will predict that the new instance belongs to class A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd6ab4-ac12-4347-a197-74712772e29f",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
